\documentclass[12pt,a4paper]{article}

%\usepackage[english]{babel}

\usepackage{amssymb,qtree,natbib,aleks,linguex}

\usepackage{amsthm}

%% note that this file depends on being processed with XeTeX
\usepackage{fontspec}
\usepackage{xltxtra,xunicode}

\usepackage{mathpazo}
% font specifications (don't overuse ;-)
\defaultfontfeatures{Mapping=tex-text} % converts LaTeX specials (``quotes'' --- dashes etc.) to unicode
\setromanfont [Ligatures={Common,Rare}, BoldFont={Fontin Bold}, ItalicFont={Fontin Italic}]{Fontin Regular}
\setsansfont [Ligatures={Common}, BoldFont={Fontin Sans Bold}, ItalicFont={Fontin Sans Italic}]{Fontin Sans}


\newcommand{\abbr}{\textsf} % how to render abbreviations like IL or Ty2
\newcommand{\stress}{\textbf} % put stress somewhere (as opposed to \emph)
\newcommand{\term}[1]{\textsf{\textbf{#1}}} % introduce a term
\newcommand{\code}{\texttt} % layout of in-line code snippets
\newcommand{\pn}{\textsf} % how to render proper names like Shrdlu
\newcommand{\url}[1]{\code{http://#1}} % how urls appear
\newcommand{\example}{\textit} % in-text examples

% commonly used phrases
\newcommand{\Disc}{\ensuremath{\mathcal{D}}} % the discourse
\newcommand{\wh}{\textsc{wh}} %

%names
\newcommand{\curt}{\pn{Curt}\mbox{ }}
\newcommand{\acurt}{\pn{Advertent Curt}\mbox{ }}
\newcommand{\prol}{\pn{Prolog}\mbox{ }}

%theorem environments
\theoremstyle{remark} \newtheorem*{termin}{Terminology} % terminology.

\bibliographystyle{plainnat}
\bibpunct{(}{)}{;}{a}{,}{,}

\author{Aleksandar Lyubenov Dimitrov\\
$\langle$\href{mailto:aleks.dimitrov@googlemail.com}{aleks.dimitrov@googlemail.com}$\rangle$}
\title{From Questions to Queries – Enhancing the Curt System by a Theory and Implementation of Embedded WH-Questions}

\usepackage{fontspec}
\usepackage[xetex,colorlinks,citecolor=magenta]{hyperref}
\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introduction}


Growing efforts have thus been made to provide a technology that is (going to
be) able to extract logical formulae from sentences of ordinary language and
establish relations between objects of its logical representation. In addition,
providing a means to compute with said representations will eventually enable
the machine-processing of an abstract concept of meaning. In doing so, the
ultimate goal may be to enable a man-made system to \emph{understand} what a
humans communicate.

Exploration of this  interesting field of linguistics has shown that
the notion of \emph{understanding} is far more than a linguistic concern, but
involves at least findings in the domain of logics, (cognitive) psychology and
probably even philosophy.

Development of exhaustive systems in this area appears to be a daunting task of
quite some scope. Therefore most approaches have been focused on providing
coverage of a small fragment of natural language often with respect to a
particular domain. Many such systems exist and they prove to be increasingly
successful. Some of them will be discussed here and presenting an extension to
one system in particular is the main matter of this Bachelor's thesis.

\subsection{Premises}

The present work will aim to provide the \curt system of
\cite{blackburnbos:cl1} with the mechanics of dealing with more than one
partition of its logical domain, viz. the ability to handle more than one
\term{possible} or \term{accessible world}. As a ground for development of this
work, the treatment of \term{embedded questions} was chosen as one that
naturally demands a possibility to account for more than one division in a
system's \emph{understanding} or representation of a universe of objects and
relations.

As the scope of a Bachelor's thesis is limited by its nature, not all of the
theoretical background can be understood without background knowledge in some
rather divergent domains. In particular, a basic familiarity with traditional
\term{natural language semantics} and \term{extensional} as well as
\term{intensional logic} frameworks will be assumed. Furthermore, a basic
acquaintance with \term{eroteric logic} will be helpful in understanding some of
the reasoning in section \ref{sec:theory}.

Some knowledge of the \prol programming language and a good overview of the
architecture of the \curt system is imperative in order to understand the
implementation itself.

The first section gives a conceptual overview, introducing the \curt
system and comparing it to other similar systems in existence. It then goes on
to explain the target domain of natural language the implementation has to
account for.
The next section concerns itself with a more detailed analysis of the theoretic
assumptions of this implementation and justifies some choices and restrictions
that had to be made due to the limited scope of this analysis. While the
third section will display and document the actual implementation on top of the
\curt system, the last section will discuss the results of this work and also
give a prospect on possible further work on the subject.


\section{Concepts}

todo: write something here... :-(

\subsection{The Curt System} \label{sec:curt}

\curt, a system written in \prol that is able to interpret basic utterances
of English and store them in expressions of first order logic, is
presented in \cite[chapter 6]{blackburnbos:cl1}. While relatively limited when
compared to other systems presented in \ref{sec:comparison} in terms of lexical
and grammatical coverage, it provides a sound basis for extended work because of
its coherent design and relative simplicity.

Besides parsing and translating utterances into logic, \curt is able to perform
basic checks for \emph{consistency} and \emph{informativity} on the resulting
formulae -- within the bounds of the tools it uses.
It can thus detect incoherent discourse and would reject a sequence of
sentences such as \emph{``Mary likes every man. Peter is a man. Mary does not
like Peter''}, claiming it found a contradiction in its input. The discourse is
then said to be \term{inconsistent} with the new input.

For every input
sentence, \pn{Curt} will also try to infer whether the current discourse would
entail the information it contains and would thus be \term{uninformative} with
respect to previous utterances – effectively allowing it to
reduce the size of its internal representation of the discourse by avoiding to
add clauses to its database that would not contribute to the overall informational value
already present in the program.

The final chapter of \cite{blackburnbos:cl1} introduces the implementation
incrementally, presenting new versions of \curt that add to the software's
feature set. Support for external inferencing via theorem provers and model
builders is added right after the first naïve implementations and
finally an ontology and a straight-forward way of parsing and answering direct
questions for noun phrases conclude its development. The theory and
implementation of this paper is meant as a replacement and enhancement for the
latter feature. This will also happen in an incremental manner and new features
will be introduced one at a time.

\subsection{Comparison of the Curt System}\label{sec:comparison}

Generally, question answering and semantic parsing are not related and seldom
interdependent in current implementations of similar systems, with a few notable
exceptions.

\cite{chat} are among  the first to attempt creating a question answering system
with deep semantic coverage. Their effort has been focused on the geographical
domain, and their implementation, dubbed \pn{CHAT-80}, is written entirely in
\prol. The lack of hardware resources of that time forced the system to be
written with efficiency in mind. Moreover, it had to maintain a statical
database of facts which was hand-crafted. The \curt system is built on  an
entirely different set of premises and aims to provide a proof-of-concept of a
more general purpose system that is also able to extend its knowledge
dynamically.

Soon after \pn{CHAT-80}, two entirely different types of systems emerged. The
first type is probably the most promising to be used on a wider scale, given
today's technological standards. Implementations are usually based on
\term{information retrieval} and the generation of question/answer pairs. Such
systems are generally referred to as a \abbr{QA} (\term{Question Answering})
systems.  Examples implementations of such systems are discussed in \cite{rama},
\cite{iesqa} and many others. Most of these seem to provide a good lexical and
grammatical coverage due to their large input corpora and
shallow interpretation techniques. The latter is also the \abbr{QA} technique's
greatest shortcoming, as no deep analysis is  performed and usually
only factoids of less then a couple of words in length can be supplied as
answers.\footnote{But see \cite{aqabtf} for an approach that aims to cover a
wider range of possible answers.}

In contrast, \pn{CHAT-80} runs all its queries against a pre-built database
without the ability to acquire new knowledge from the discourse. While a
\abbr{QA} implementation will typically just acquire knowledge by consuming
more input and analysing its statistical properties, programs employing deep
semantic analysis will have to check their input for logical contradictions in
to maintain their database in a reasonable\footnote{FIXME pun intended, but
appropriate? %todo
} state.

\cite{prontoqa} introduce the \pn{Pronto QA System}, which couples traditional
corpus-based \abbr{QA} techniques with deep semantic parsing based on
\term{Discourse Representation Theory}.

A very interesting project, called \pn{Godot} is introduced in \cite{godot}.
\pn{Godot} is a so-called \term{embodied agent}, a robot with a sophisticated
software driving interaction with the outer world. As such its conception of
discourse not only relies on spoken dialogue, but also on sensory input.
\pn{Godot} is focused on executing orders -- after evaluating their feasibility
in its particular discourse model -- and does so far not support the answering
of questions about its state.

\subsection{Extending the Curt System}

At the end of \cite{blackburnbos:cl1}, \curt is able to cope with a small
grammar and provides some features for interaction in natural
language. It does only understand basic extensional transitive and intransitive
verbs and its support for question answering remains limited.
Anaphora resolution still remains an open issue.

In the course of this thesis, a new version of \curt will be developed, called
\acurt. This version is not only aware of its own state, but can also gather
information about the individuals it knows about. Furthermore, \acurt is
able to account for several possible readings of a certain sentence at once and
in parallel, which is a side-effect of the introduction of \term{intensionality}
into the system.

\acurt is able to parse and, according to the theoretical background of section
\ref{sec:theory}, correctly interpret sentences as the ones in
\ref{ex:whemba}-\ref{ex:whembc}.

\ex.
\a.  Mia knows Vincent snorts.\label{ex:whemba}
\b.  Mia knows who snorts.
\b.  Vincent believes that Mia likes Jody.\label{ex:whembc}

For this to work, the internal storage of \curt will have to be restructured
significantly in order to deal with more than one possible world or situation.
Its grammar will have to be enhanced so that it can handle \wh-embedding verbs
like `know' and `believe' and its inferencing mechanisms will have to be
enhanced.

The following section explains the problems at hand and existing solutions. A
subset thereof will be implemented in section \ref{sec:implementation}, which
will also raise some pragmatic issues discussed later on in section
\ref{sec:discussion}.

\section{Theory}\label{sec:theory}

This section first gives an overview over the terminology that will be used for
the discussion of the formal treatment of questions. It then elaborates on the
differences between different logical formalisms employed in the treatment of
natural language questions. After a small overview on the types of questions
(and pointing out the subset of questions that will be treated), %fixme maybe a
% bit sloppy
the discussion
turns to how those questions are best treated in the given formalism.

The reader should note that all choices presented in this section have been made
with the implementation of section \label{sec:implementation} in mind.
% todo talk a bit more


\subsection{Terminology}

Following \cite{gs:q}, we will not use the natural English word
``question'' in its traditional sense, but distinguish between \term{questions},
\term{interrogative sentences} and \term{interrogative acts} in the following
way:

\begin{termin}
  An \term{interrogative} is a certain type of sentence in natural language
  distinguished by certain characteristics\footnote{To quote \cite{gs:q}: \quote{[An
  interrogative sentence is] characterized by word order, intonation, question
  mark, the occurrence of interrogative pronouns}.}
  whereas an \term{interrogative act} refers to the utterance of an
  \term{interrogative}. Finally, a
  \term{question} will denote the semantic entity uttered by the
  \term{interrogative act}, as it will be introduced in section
  \ref{sec:protoq}
\end{termin}

The following abbreviations will be used: 
\abbr{Ty2} stands for two-sorted type logic\footnote{See \cite{gallin:ty2} for a
discussion and \cite{gs:sqpa} for its usage in describing the semantics of
questions}. \abbr{IL} stands for intensional logic\footnote{As used by \cite{ptq}}. 

%todo OUTLINE Presenting a conceptual overview, while arguing for and against stuff.

First we will present a brief overview of the considerations regarding the
choice of an appropriate formalism for the system in section \ref{sec:formal}
to then compare it with already existing implementations of question answering
systems in \ref{sec:othercrap}.

\subsection{Formalism}\label{sec:formal}

% FIXME if we have a `Terminology' section, all those `henceforths' aren't really
% necessary anymore.

Most of the traditional literature in natural language semantics follows
\cite{ptq} and thus also makes use of its underlying formalism,
\emph{Intensional Logic} (henceforth \abbr{IL}). \cite{gs:sqpa} (and many subsequent
publications) however also use two-sorted type logic (henceforth \abbr{Ty2}) as
proposed in \cite{gallin:ty2}. \cite{z:ilty2} discusses the differences and
similarities in expressive power between \abbr{Ty2} and \abbr{IL} and comes to
the conclusion that the set of expressions contained in the former but not in
the latter might not be relevant for the treatment of natural language
semantics. Although he proposes a translation scheme between both languages,
translation from \abbr{Ty2} to \abbr{IL} seems to sometimes produce very complex
\abbr{IL} terms and is therefore avoided here. In fact, \abbr{IL} will be only
marginally relevant for the presentation of \acurt – only the type system
presented in \cite{ptq} is carried over.

% OK till now, but the rest is a fixme :-(

Since this paper is not concerned with possible extensions of the underlying
theories of treating natural language questions, but rather with their
implementation in the programming language \pn{Prolog} several additional
constraints have to be considered. Among them the \emph{feasibility} of any
possible approach takes highest precedence.

To quote \cite{blackburnbos:cl1}:

\begin{quote}
  Questions, unlike assertions, don't have truth-values, so it would be
  misleading to represent them as ordinary formulas.
\end{quote}

It is important to note that this claim is not undisputed and
\cite{karttunen:1977}, argues against it. The present approach, however will
base itself on this assumption and extend it by more formal approaches than the
one given by Blackburn \& Bos. Specifically, the work by J. Groenendijk and M. Stokhof
will lay ground to the implementation. But in order to realise their formal
discussions computationally, modifications will have to be made, and even
compromises.

As was already mentioned in \ref{sec:curt}, Curt is based on an
implementation and the use of external tools only capable of treating first
order logic – an extensional framework. \prol on the other hand, is a language
that can very well make use of higher order formalisms for
calculation\footnote{The two most popular predicates in \prol used for
implementing higher-order logic are
\code{call/n} and \code{apply/3}. This paper is based on \pn{SWI-Prolog} which
provides an implementation of the former, but not of the latter. See
\cite{naish:prolhio} for a discussion of higher order functional programming in
\prol.}.

While there exist inferencing tools for modal logic\footnote{See %todo todo and todo 
for discussions. The interested reader is also referred to \pn{Molle}
(\url{http://molle.sf.net}), a modal theorem prover that comes with a graphical user
interface which allows interactive investigation of the constructed indices.},
a restructuring of the \pn{Curt} system to take advantage of them would be
beyond the scope of this thesis.

It was therefore decided to avoid modal logic and implement a pragmatic approach
to representing the indices of higher-order logic in \prol in section
\ref{sec:indices}. This logic however has to be augmented with question
operators as already used by \cite{karttunen:1977}. % todo: writeme!

\cite{g:is} presents an approach to implementing inquisitive semantics in
predicate logic.

\subsection{On the Proper Treatment of Questions}

Question semantics are an interesting subproblem of modern research on natural
language semantics. While traditional approaches based on \abbr{IL} and newer
accounts also employ plain extensional logic, % todo: which ones 
the treatment
of questions seems to demand that we introduce a new kind of logic formalism.
But as interesting topics go, the semantics of questions has attracted many
different views on this issue.

Often question semantics has been reduced to a problem of
pragmatics, treating direct interrogatives as nothing more than a
paraphrase of embedded interrogatives.\cite{tichy}
even goes as far as claiming equality in semantic (truth) value between
indicatives and interrogatives. The benefit of such an approach would be the
strict reliance on traditional analyses, where interrogatives would only infer a
different `attitude' in the speaker's utterance. Putting this attitude into
context and making it yield the correct results would then be left to
pragmatics.

This approach has been challenged and proven unfeasible by \cite{gs:q},
who have also proposed interesting extensions
to the existing logic frameworks used in natural language semantics.
More recent publications, such as \cite{gal:tmbi}
address this topic and aim to introduce notions of \term{information change
potential} as opposed to the traditional focus of natural language semantics on
\term{truth values}.

The present work will rely on \cite{gs:q} for providing the main guidelines for
the theoretic aspects and also lend from earlier works, most importantly
\cite{gs:sqpa}\footnotemark. Later on, in section \ref{sec:altq} we will also
discuss the very newest (at the time of writing) developments in question
semantics, depicted in \cite{g:is}.

\footnotetext{\cite{gs:sqpa} is actually a series of three articles
that have appeared before. Among them, we will mostly consider \cite{gs:sawhq}.
Both, the earlier paper and the later dissertation (and many other papers
originating in Amsterdam) have been kindly made
available electronically, free of charge, by the Universiteit van Amsterdam at
the following address: \url{http://dare.uva.nl}}


\subsubsection{Pragmatics and Semantics of Questions}

In choosing to treat only embedded questions, we can escape most pragmatic
considerations and focus on the (implementation of) pure semantics of
interrogatives.

\subsection{Classification of Interrogatives}

When treating questions one will be confronted with many different
categorizations of questions. One of the first distinctions to make is the one
between \term{embedded questions} as in \ref{ex:embed} and \term{direct
questions} shown in \ref{ex:direct}.

\ex. \a. John knows \emph{whether this sentence contains an embedded
question}.\label{ex:embed}
\b. Does this sentence pose a direct question?\label{ex:direct}

As indicated already by the title, this paper will concern itself with the
treatment of the former and only briefly comment on the latter. The reasons for
this are numerous  %fixme I need a synonym for that
and this section is going to name the most important ones.

Early literature, such as \cite{karttunen:1977} only regards embedded
\wh-phrases, treating direct questions as semantically equivalent. To quote
Karttunen:

\begin{quote}A direct question can be treated as semantically equivalent to a
certain kind of declarative sentence containing the corresponding indirect
question embedded under  a suitable `performative' verb.\end{quote}

Using this strategy, Karttunen escapes the treatment of direct  questions and
thus gives an approach for indirect questions only.

\subsubsection{An Ontology of Embedding Verbs}

\cite{karttunen:1977} introduces means of classification for \wh-embedding
verbs, the nature of which \cite{lahiri:diss} covers in a much broader scope.
The different verb classes ask for different strategies of treating the
\wh-clauses they embed and also pose different restrictions on the type of
clause they expect.

The present work will not consider a full analysis of \wh-embedding verbs, but
confine itself on a few ones, namely \example{know}, \example{think} and
\example{believe}. The grammar implementation of \acurt allows for \wh-embedding
verbs to have a \code{type} field, determining their semantic denotation. The two
types used so far are \code{assert} for assertive verbs such as \example{know}
and \code{stipul} for stipulating verbs, such as \example{believe} and
\example{think}.

\subsubsection{Grammatic Constraints}

With this ontology in mind, the next step is to analyse and enumerate the sorts
of grammatic constructions that are to be treated. The following examples will
illustrate them.

\begin{itemize}
  \item Alternative Questions
  \ex. \a. Mia \emph{knows} whether Vincent snorts.
  \b. * Mia \emph{believes} whether Vincent snorts.
  \b. * Mia \emph{thinks} whether Vincent snorts.
  
  \item Enumerative Questions
  \ex. \a.  Mia \emph{knows} who snorts.
  \b. * Mia \emph{believes} who snorts.
  \b. * Mia \emph{thinks} who snorts.

  \item Embedding Propositions
  \ex. \label{ex:stipul}
  \a. Mia \emph{believes} Vincent snorts.
  \b. * Mia \emph{believes} who snorts.

\end{itemize}

An important observation to be made here is that only \emph{assertive} verbs can
embed real questions. \emph{Stipulating} verbs only embed \emph{propositions} as
in \ref{ex:stipul}.
Nevertheless, both are treated in the following analysis, but with a focus on
the treatment of assertive \wh-embedding verbs.


\subsubsection{Extensional WH-embedding Verbs}

Like \emph{know}.

We first derive know(john,all(X,imp(woman(X),love(X,john)))) from the syntax of
john knows whether every woman loves john, then we see if
all(X,imp(woman(X),love(X,john))) is valid (uninformative) and ridicule John, if
it's not valid and not consistent, assert his knowledge of the fact that it's
not true. If it's true, we assert he knows that.

For whether we can ridicule him if it's not true (inconsistent).
The MB/TP do a comparison \Disc to all(X,imp(woman(X),love(X,john)))

\subsubsection{Intensional WH-embedding Verbs}

Like \emph{believe}.

\section{Implementation}

\subsubsection{Advertent Curt}

\acurt lends its name from the fact that it is not only aware of its own
knowledge and presuppositions, but `knows' about what individuals in its
model of the world are aware of. It is not in this sense a question
\emph{answering} system, but it may be seen as an early effort towards providing
such a system on a more sophisticated scale. While section \ref{sec:altq} shows
how direct questions can be integrated into the system with relative ease, focus
is still on providing a feasible method of implementing intensionality in what
is mostly a first-order logic computing environment.


It is also not constrained to being useful in a particular domain, like
\pn{CHAT-80} is.

\subsection{Modality and Possible Worlds}
\label{sec:indices}

We have seen that some embedding verbs may not be interpreted without
implementing a higher order formalism that is able to model the notion of
\emph{possible} and \emph{accessible} worlds. While foobar %fixme! Nelken &
% Francez 2001
argue for an extensional treatment of questions, they already % n & f 2006
retract their claims and admit that a ``minimal account of intensionality'' has
to be assumed. While they propose a two-world system later adopted in
\cite{g:is}, this is not going to suffice if we want to model each individual's
knowledge in order to be able to discriminate people's knowledge and beliefs.
%fixme bla bla

The underlying theory for 

\subsubsection{Representing Intensionality in \prol}

\prol programs can be self-modifying, or dynamic. In this way the program is
able to change its own state and thus store information.

\subsubsection{Disjunction and Ambiguity}
Consider the following sentences:

\ex. \label{ex:disjunction} \a. Mia or Jody dances
\b. Either Butch snores or Vincent is using the chainsaw

\pn{Helpful Curt}, with its unpartitioned logical space and its lack of
the awareness of more than one (possible) world, would generate only one model
to represent the facts of \ref{ex:disjunction}. It is therefore only able to
generate \emph{one} possible answer to both questions, effectively accounting only
for one possible constituent of the disjunction, prefixing it with a `maybe' to
indicate its uncertainty.

Another example where \curt has to sacrifice exhaustiveness over its one-world
representation of the world is given in \ref{ex:ambig}

\ex.\label{ex:ambig} Every boxer likes a woman.

This will generally generate two readings, but only one model -- with only one
world. And further discourse will have to choose between one of the readings and
stick with the minimal model constructed by the model builder. This is not
really satisfactory and extending the dimensions of knowledge within \curt seems
necessary in order to treat such examples.

The previous work on \acurt enables it to generate a \term{choice point} -- and
moreover, not pursue only one path of it, but both at the same time, by
generating more than one world in its model.
Unfortunately, this will build up very large models over time and computations
with it might prove to be very complex and resource demanding. Adding such a
functionality to the system, however, is not a hard task and hopefully the
technique employed here can be further refined. %todo: maybe add a footnote
%about future prospects or so

\subsubsection{Defining the Grammar Rules}

\curt parses sentences of natural language using an enhanced version of \pn{Cooper
storage}\footnote{See \cite{cooper:storage2} for the original implementation.} as
presented in \cite{keller:storage}. \cite{blackburnbos:cl1} call this version
\pn{Keller Storage}. That name will be used from here % FIXME sucks. Please change
to refer to this particular implementation as presented in
\cite{blackburnbos:cl1}. 

\pn{Keller Storage} is already quite capable
of dealing with more complex constituents such as nested noun phrases, but it
has its limitations. In particular, it can only handle quantifier scope
ambiguities and does not take negation into account. Moreover, it overgenerates
with some quantifier scope ambiguities\footnote{\cite{blackburnbos:cl1} mention
sentences such as \ref{ex:kellersucks}, where Keller Storage produces six
instead of the desired five readings.
\ex. One criminal knows every owner of a hash bar\label{ex:kellersucks}

Clearly, \example{a hash bar} cannot take scope over \example{every owner}, but
Keller Storage predicts this reading.}.

In order to cope with more complicated quantifier configurations, where
constraints need to be enforced, and with other kinds of ambiguities,
Blackburn and Bos present an approach utilizing underspecified representations and
dominance relations, \pn{Hole Semantics}\footnote{Also presented in % todo:cite
%Bos' paper
}. However none of the cases discussed so far would require the enhanced
expressive power of \pn{Hole Semantics} it was decided to not change the \curt
implementation's current architecture which employs \pn{Keller Storage}.

Enhancing the grammatic rules of the \curt system to cope with
proposition-embedding verbs is made trivial by its elaborate grammatical back
end. \ref{ex:kel1} is an example of the logic behind the grammar that is put to
use.

\ex. \label{ex:kel1} Mia knows whether Vincent snorts.\\
\Tree
[.$t$ [.$T$ { $\lambda X.X(Mia)$\\Mia } ]
[.$IV$ [.{$IV/\bar{t}$} { $\lambda X.know(X)$\\knows } ]
[.{$\bar{t}$} [.$\bar{t}/t$ whether ] [.{ $t$\\$snort(Vincent)$ } 
[.$T$ { $\lambda X.X(Vincent)$\\Vincent } ]
[.$IV$ { $\lambda X.snort(X)$\\snorts } ] ] ] ] ]

\footnotetext{Note that \ref{ex:kel1} is shown using the same syntactic type system used in
\cite{gs:sawhq}, which extends the system given in \cite{ptq} by $\bar{t}$ to
denote embedded \wh-constituents.}

\subsection{Treatment of Baker Ambiguities}

\subsection{Alternative Questions – Inquisitive Semantics}\label{sec:altq}

\cite{g:is} introduces a novel approach to treating questions in natural
semantics: \pn{Inquisitive Semantics}. He presents a new logic
formalism aimed at providing a wider coverage of the intentions of question in
human language. The main source of the ``inquisitiveness'' of statements is
given by the interpretation of \emph{disjunction}. We will now show how to
incorporate this novel approach into the \pn{Curt} system.

We will, however depart from the path we have been following throughout this
paper and first implement a theory for direct questions. Only then will we extend
it to also cover embedded alternative questions.

\section{Discussion}\label{sec:discussion}

We have seen, the Curt system is quite capable of treating questions this way.
Having implemented modality and possible worlds in such a fashion, let's go on
and implement some even cooler stuff (tense, aspect, negation, comparatives,
anaphora). Basing all this on a nice implementation of DRT (discussed in
\cite{kampreyle:drt}) like the one given in \cite{blackburnbos:cl2} might be
interesting. The Pronto \abbr{QA} system of \cite{prontoqa} already defines a
means of representing questions and queries against a Discourse Representation
Structure.

\section{Appendix}

\subsection{The Source Code}

\subsection{Whatnot}

\bibliography{aleksbib}

\end{document}

